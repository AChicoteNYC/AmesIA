{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models on Ames Real Estate Data\n",
    "\n",
    "_Author: Alex Chicote (NYC)_\n",
    "\n",
    "---\n",
    "<img src=\"./photo303159.jpeg\" style=\"float: center; margin: 20px; height: 300px\">\n",
    "\n",
    "        Is it possible to predict the price of sale for a real estate unit in Ames IA?\n",
    "\n",
    "        What are the most important factors to determine it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of Action. Feature Engineering\n",
    "\n",
    "### Steps:\n",
    "\n",
    "\n",
    "\n",
    "   - [1. Importing all the modules necessary.](#importing)\n",
    "   - [2. Fixing columns names.](#nulsimes) \n",
    "   - [3. Finding and replacing nulls.](#nulsimes)\n",
    "   - [4. Create dummies for all object columns.](#dummies)\n",
    "   - [5. Repeat the process for test set.](#second_try)\n",
    "   - [6. Making sure all features are the same in all sets( except for saleprice and sale_condition.](#killing)\n",
    "   - [7. Save train and test as a csv.](#vesasaberque)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='importing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LogisticRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MoSold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/fcbnyc/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MoSold'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c73eec79a95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MoSold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/fcbnyc/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fcbnyc/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fcbnyc/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fcbnyc/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fcbnyc/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MoSold'"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train['MoSold'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nulsimes'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You better be zero 0\n",
      "You better be zero 0\n"
     ]
    }
   ],
   "source": [
    "##loading data(train)\n",
    "file ='train.csv'\n",
    "train = pd.read_csv(file)\n",
    "train.columns = [x.lower().replace(' ', '_') for x in train.columns]\n",
    "train.shape\n",
    "numero_train = list(train.select_dtypes(include=['int64', 'float64']).columns)\n",
    "object_train = list(train.select_dtypes(include=['object']).columns)\n",
    "##making sure it is correct: must be zero\n",
    "secure = len(train.columns) - len(numero_train) - len(object_train)\n",
    "print('You better be zero', secure)\n",
    "##I do not need to do anything with \n",
    "##separating features with nulls by dtypes\n",
    "numeric_nuls = []\n",
    "for item in numero_train:\n",
    "    if train[item].isnull().sum() > 0:\n",
    "        t = tuple([item, train[item].isnull().sum()])\n",
    "        numeric_nuls.append(t)\n",
    "    numeric_nuls.sort(key=lambda x: x[1], reverse=True)\n",
    "object_nuls = []\n",
    "for item in object_train:\n",
    "    if train[item].isnull().sum() > 0:\n",
    "        t = tuple([item, train[item].isnull().sum()])\n",
    "        object_nuls.append(t)\n",
    "    object_nuls.sort(key=lambda x: x[1], reverse=True)\n",
    "## Feature Engineering and replacing nuls\n",
    "MEAN = train['lot_frontage'].mean()\n",
    "train['lot_frontage'] = train['lot_frontage'].fillna(MEAN)\n",
    "train['garage_yr_blt'] = train['garage_yr_blt'].replace(2207, 2007)\n",
    "###It is a tuple, IDIOT\n",
    "for item in object_nuls:\n",
    "    cosa = item[0]\n",
    "    if 'garage_' in cosa:\n",
    "        train[cosa] = train[cosa].fillna(0)\n",
    "for item in numeric_nuls:\n",
    "    cosa = item[0]\n",
    "    if 'garage_' in cosa:\n",
    "        train[cosa] = train[cosa].fillna(0)\n",
    "## I will fill with zeros the rest of numerics\n",
    "for item in numeric_nuls:\n",
    "    cosa = item[0]\n",
    "    train[cosa] = train[cosa].fillna(0)\n",
    "###I fill nuls with zeros for the rest of ojects \n",
    "for item in object_nuls:\n",
    "    melanina = item[0]\n",
    "    train[melanina] = train[melanina].fillna('0')     \n",
    "print('You better be zero',(train.isnull().sum() > 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has to be zero 0\n",
      "Has to be zero 0\n"
     ]
    }
   ],
   "source": [
    "filename ='test.csv'\n",
    "test = pd.read_csv(filename)\n",
    "test.columns = [x.lower().replace(' ', '_') for x in test.columns]\n",
    "test.shape\n",
    "numero_test = list(test.select_dtypes(include=['int64', 'float64']).columns)\n",
    "\n",
    "object_test = list(test.select_dtypes(include=['object']).columns)\n",
    "\n",
    "##making sure it is correct: must be zero\n",
    "secure = len(test.columns) - len(numero_test) - len(object_test)\n",
    "print('Has to be zero', secure)\n",
    "\n",
    "##I do not need to do anything with \n",
    "train[numero_test].describe()\n",
    "numeric_nuls_test = []\n",
    "for item in numero_test:\n",
    "    if test[item].isnull().sum() > 0:\n",
    "        t = tuple([item, test[item].isnull().sum()])\n",
    "        numeric_nuls_test.append(t)\n",
    "    numeric_nuls_test.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "object_nuls_test = []\n",
    "for item in object_test:\n",
    "    if test[item].isnull().sum() > 0:\n",
    "        t = tuple([item, test[item].isnull().sum()])\n",
    "        object_nuls_test.append(t)\n",
    "    object_nuls_test.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for item in object_nuls_test:\n",
    "    cosa = item[0]\n",
    "    if 'garage_' in cosa:\n",
    "        test[cosa] = test[cosa].fillna(0)\n",
    "for item in numeric_nuls_test:\n",
    "    cosa = item[0]\n",
    "    if 'garage_' in cosa:\n",
    "        test[cosa] = test[cosa].fillna(0)\n",
    "MEAN = test['lot_frontage'].mean()\n",
    "test['lot_frontage'] = test['lot_frontage'].fillna(MEAN)   \n",
    "###It is a tuple, IDIOT\n",
    "## I will fill with zeros the rest of numerics and non_numerics\n",
    "for item in numeric_nuls_test:\n",
    "    cosa = item[0]\n",
    "    test[cosa] = test[cosa].fillna(0)\n",
    "for item in object_nuls_test:\n",
    "    melanina = item[0]\n",
    "    test[melanina] = test[melanina].fillna('0')\n",
    "print('Has to be zero',(test.isnull().sum() > 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure we work with same features in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saleprice', 'sale_condition'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "##Sale_condition feature does not exist in the test dataset so I would eliminate it\n",
    "TRAIN = set(train.columns)\n",
    "TEST = set(test.columns)\n",
    "diff = TRAIN - TEST\n",
    "print(diff)\n",
    "DIFF = TEST - TRAIN\n",
    "print(DIFF)\n",
    "z = train['sale_condition']\n",
    "#train.drop('sale_condition', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dummies'></a>\n",
    "## get dummies going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "object_train.remove('sale_condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2051, 308) (879, 289)\n"
     ]
    }
   ],
   "source": [
    "test = pd.get_dummies(test, columns=object_test)\n",
    "train = pd.get_dummies(train, columns=object_train)    \n",
    "print(train.shape, test.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='killing'></a>\n",
    "## Finaly, I want eliminate the features that are not in set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'electrical_Mix', 'roof_matl_ClyTile', 'functional_Sal', 'pool_qc_Fa', 'heating_Wall', 'exterior_2nd_Stone', 'roof_matl_Membran', 'misc_feature_TenC', 'misc_feature_Elev', 'functional_Sev', 'neighborhood_GrnHill', 'heating_OthW', 'condition_2_Artery', 'utilities_NoSeWa', 'ms_zoning_A (agr)', 'heating_qc_Po', 'garage_qual_Ex', 'condition_2_RRAn', 'exterior_1st_CBlock', 'bsmt_cond_Ex', 'exterior_1st_Stone', 'condition_2_RRNn', 'saleprice', 'neighborhood_Landmrk', 'exterior_1st_ImStucc', 'condition_2_RRAe', 'pool_qc_Gd', 'bsmt_cond_Po', 'sale_condition'} 29\n",
      "{'electrical_0', 'kitchen_qual_Po', 'roof_matl_Metal', 'exterior_2nd_Other', 'exterior_1st_PreCast', 'exterior_2nd_PreCast', 'sale_type_VWD', 'roof_matl_Roll', 'mas_vnr_type_CBlock', 'heating_Floor'} 10\n"
     ]
    }
   ],
   "source": [
    "##Finaly, I want eliminate the features that are not in set.\n",
    "TRAIN = set(train.columns)\n",
    "TEST = set(test.columns)\n",
    "diff = TRAIN - TEST\n",
    "diff = diff\n",
    "print(diff, len(diff))\n",
    "DIFF = TEST - TRAIN\n",
    "print(DIFF, len(DIFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "diff = list(diff)\n",
    "print(len(diff))\n",
    "diff = [c for c in diff if c != 'saleprice']\n",
    "diff = [c for c in train.columns if c not in diff]\n",
    "diff.append('sale_condition')\n",
    "print(len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "279\n"
     ]
    }
   ],
   "source": [
    "DIFF = list(DIFF)\n",
    "print(len(DIFF))\n",
    "\n",
    "DIFF = [c for c in test.columns if c not in DIFF]\n",
    "print(len(DIFF))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vesasaberque'></a>\n",
    "## Saving final train and final set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Saving final dataseta\n",
    "train[diff].to_csv('final_train.csv', index=False, encoding = 'utf-8' )\n",
    "test[DIFF].to_csv('final_test.csv', index=False, encoding= 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
